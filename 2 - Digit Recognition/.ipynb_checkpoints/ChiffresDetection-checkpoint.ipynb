{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement données d'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement de la librairie\n",
    "from fastai2.vision.all import *\n",
    "\n",
    "# Récupération des images\n",
    "path = Path('/storage/data/mnist_sample')\n",
    "threes = (path/'train'/'3').ls().sorted()\n",
    "sevens = (path/'train'/'7').ls().sorted()\n",
    "three_tensor = [tensor(Image.open(o)) for o in threes]\n",
    "seven_tensor = [tensor(Image.open(o)) for o in sevens]\n",
    "\n",
    "# On ramène les valeurs entre 0 et 255 à leur équivalent entre 0 et 1. \n",
    "# On simplifie la liste pour obtenir une liste ??\n",
    "stacked_threes = torch.stack(three_tensor).float()/255\n",
    "stacked_sevens = torch.stack(seven_tensor).float()/255\n",
    "\n",
    "# On regroupe ces informations dans un seul tensor\n",
    "# On crée également un tensor avec les valeur attendues (1 c'est un trois, 0 ce n'est pas un trois)\n",
    "stacked_digits = torch.cat([stacked_threes, stacked_sevens])\n",
    "stacked_labels = tensor([1]*len(threes) + [0]*len(sevens))\n",
    "\n",
    "# On transforme les tableaux de 28 par 28 pixel en une liste de 784 pixels pour simplifier le traitement \n",
    "# On formate les deux tensors pour être équivalent \n",
    "train_x = stacked_digits.view(-1, 28*28)\n",
    "train_y = stacked_labels.unsqueeze(1)\n",
    "train_dataset = list(zip(train_x,train_y))\n",
    "\n",
    "# On met en batch \n",
    "train_dl = DataLoader(train_dataset,batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement données de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On charge les images valides. \n",
    "valid_3_tens = torch.stack([tensor(Image.open(o)) for o in (path/'valid'/'3').ls()])\n",
    "valid_3_tens = valid_3_tens.float()/255\n",
    "valid_7_tens = torch.stack([tensor(Image.open(o)) for o in (path/'valid'/'7').ls()])\n",
    "valid_7_tens = valid_7_tens.float()/255\n",
    "\n",
    "# On concatène et crée la liste de label\n",
    "valid_x = torch.cat([valid_3_tens, valid_7_tens]).view(-1, 28*28)\n",
    "valid_y = tensor([1]*len(valid_3_tens) + [0]*len(valid_7_tens)).unsqueeze(1)\n",
    "valid_dataset = list(zip(valid_x,valid_y))\n",
    "\n",
    "#On met en batch\n",
    "valid_dl = DataLoader(valid_dataset, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Définition des méthodes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initialisation des paramètres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On rends un tensor de la taille demandée avec des paramètres définis au hasard. \n",
    "# On positionne la propriété requires_grad pour pouvoir calculer le gradient par la suite.\n",
    "def init_params(size, std=1.0):\n",
    "    return (torch.randn(size)*std).requires_grad_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fonction de calcul de coût (loss function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On utilise le sigmoid pour ramener le résultat obtenu par le model à sa valeur entre 0 et 1\n",
    "# On renvoit la moyenne des distances d'erreur\n",
    "def mnist_loss(activations_01, targets):\n",
    "        activations_01 = activations_01.sigmoid()\n",
    "        distances = torch.where(targets==1,1-activations_01,activations_01)\n",
    "        return distances.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul de la performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On calcul le nombre de prédictions correctes \n",
    "def accuracy(activations, targets):\n",
    "    predictions = activations > 0\n",
    "    corrects = (predictions == targets)\n",
    "    return corrects.float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul du gradient "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On applique le model puis on appel backward (propagation) pour calculer l'ensemble des gradients\n",
    "def compute_gradient(xb, yb, model, loss_func): \n",
    "    predictions = model(xb)\n",
    "    loss = loss_func(predictions, yb)\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Définition du model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On utilise un modèle linéaire ici avec simplement la multiplication de chaque pixel par le paramètre correspondant. \n",
    "# On a 784 pixel et 784 paramètres. Petit à petit les paramètres en face de pixel hautement probable pour un trois vont \n",
    "# être augmenter et inversement. \n",
    "# params[0] contient les poids et params[1] le biais (pour stabiliser ?)\n",
    "def linear_model(xb):\n",
    "    return xb@weights + bias"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Définition des méthodes époques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On parcours les mini-batch et on va calculer les gradients puis appliquer la learning rate sur chaque paramètre\n",
    "def train_epoch(model, lr, params):\n",
    "    for xb, yb in train_dl:\n",
    "        compute_gradient(xb,yb,model,mnist_loss)\n",
    "        for p in params:\n",
    "            p.data -= p.grad * lr # On modifie chaque paramètre en fonction du gradient et du learning rate défini\n",
    "            p.grad.zero_() # remise à zéros du gradient pour itération suivante. \n",
    "\n",
    "# On parcours les mini batchs du dataset de validation et on calcule le taux de réussite avec le model actuel. \n",
    "# On retourne la moyenne de ces taux de réussite\n",
    "def validate_epoch(model):\n",
    "        accs = [accuracy(model(xb), yb) for xb,yb in valid_dl]\n",
    "        return round(torch.stack(accs).mean().item(), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# On entraine le model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5853 0.8007 0.891 0.9203 0.9398 0.9472 0.9516 0.954 0.956 0.9584 0.9594 0.9613 0.9628 0.9638 0.9647 0.9657 0.9657 0.9667 0.9677 0.9687 "
     ]
    }
   ],
   "source": [
    "lr = 1\n",
    "weights = init_params((28*28,1))\n",
    "bias = init_params(1)\n",
    "params = (weights,bias)\n",
    "\n",
    "for i in range(20):\n",
    "    train_epoch(linear_model, lr, params)\n",
    "    print(validate_epoch(linear_model), end=' ')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
