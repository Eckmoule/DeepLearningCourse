{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement données d'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Chargement de la librairie\n",
    "from fastai2.vision.all import *\n",
    "\n",
    "# Récupération des images\n",
    "path = Path('/storage/data/mnist_sample')\n",
    "threes = (path/'train'/'3').ls().sorted()\n",
    "sevens = (path/'train'/'7').ls().sorted()\n",
    "three_tensor = [tensor(Image.open(o)) for o in threes]\n",
    "seven_tensor = [tensor(Image.open(o)) for o in sevens]\n",
    "\n",
    "# On ramène les valeurs entre 0 et 255 à leur équivalent entre 0 et 1. \n",
    "# On simplifie la liste pour obtenir une liste ??\n",
    "stacked_threes = torch.stack(three_tensor).float()/255\n",
    "stacked_sevens = torch.stack(seven_tensor).float()/255\n",
    "\n",
    "# On regroupe ces informations dans un seul tensor\n",
    "# On crée également un tensor avec les valeur attendues (1 c'est un trois, 0 ce n'est pas un trois)\n",
    "stacked_digits = torch.cat([stacked_threes, stacked_sevens])\n",
    "stacked_labels = tensor([1]*len(threes) + [0]*len(sevens))\n",
    "\n",
    "# On transforme les tableaux de 28 par 28 pixel en une liste de 784 pixels pour simplifier le traitement \n",
    "# On formate les deux tensors pour être équivalent \n",
    "train_x = stacked_digits.view(-1, 28*28)\n",
    "train_y = stacked_labels.unsqueeze(1)\n",
    "train_dataset = list(zip(train_x,train_y))\n",
    "\n",
    "# On met en batch \n",
    "train_dl = DataLoader(train_dataset,batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Chargement données de validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On charge les images valides. \n",
    "valid_3_tens = torch.stack([tensor(Image.open(o)) for o in (path/'valid'/'3').ls()])\n",
    "valid_3_tens = valid_3_tens.float()/255\n",
    "valid_7_tens = torch.stack([tensor(Image.open(o)) for o in (path/'valid'/'7').ls()])\n",
    "valid_7_tens = valid_7_tens.float()/255\n",
    "\n",
    "# On concatène et crée la liste de label\n",
    "valid_x = torch.cat([valid_3_tens, valid_7_tens]).view(-1, 28*28)\n",
    "valid_y = tensor([1]*len(valid_3_tens) + [0]*len(valid_7_tens)).unsqueeze(1)\n",
    "valid_dataset = list(zip(valid_x,valid_y))\n",
    "\n",
    "#On met en batch\n",
    "valid_dl = DataLoader(valid_dataset, batch_size=256)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regroupement des données "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "dls = DataLoaders(train_dl,valid_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Définition des méthodes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul de cout (loss function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On utilise le sigmoid pour ramener le résultat obtenu par le model à sa valeur entre 0 et 1\n",
    "# On renvoit la moyenne des distances d'erreur\n",
    "def mnist_loss(activations_01, targets):\n",
    "        activations_01 = activations_01.sigmoid()\n",
    "        distances = torch.where(targets==1,1-activations_01,activations_01)\n",
    "        return distances.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul de la performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On calcul le nombre de prédictions correctes \n",
    "def accuracy(activations, targets):\n",
    "    predictions = activations > 0\n",
    "    corrects = (predictions == targets)\n",
    "    return corrects.float().mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcul du gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On applique le model puis on appel backward (propagation) pour calculer l'ensemble des gradients\n",
    "def compute_gradient(xb, yb, model, loss_func): \n",
    "    predictions = model(xb)\n",
    "    loss = loss_func(predictions, yb)\n",
    "    loss.backward()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les classes "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gestion des gradients "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SGDOptimizer: \n",
    "    \n",
    "    def __init__(self,model,lr):\n",
    "        self.params = list(model.params)\n",
    "        self.lr = lr\n",
    "\n",
    "    # On modifie chaque paramètre en fonction du gradient et du learning rate défini\n",
    "    def adjust_params(self):\n",
    "        for param_tensor in self.params:\n",
    "            param_tensor.data -= param_tensor.grad.data * self.lr  \n",
    "            \n",
    "    # remise à zéros du gradient pour itération suivante. \n",
    "    def zero_grad(self):\n",
    "        for param_tensor in self.params:\n",
    "            param_tensor.grad.zero_()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Le model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LinearModel:\n",
    "    \n",
    "    @staticmethod\n",
    "    def init_params(size):\n",
    "        return torch.randn(size).requires_grad_()\n",
    "    \n",
    "    # Initialisation des paramètres remplace init_params\n",
    "    def __init__(self):\n",
    "        self.params = (LinearModel.init_params(28*28), LinearModel.init_params(1))\n",
    "    \n",
    "    # Application du model remplace linear_model\n",
    "    def __call__(self, inputs):\n",
    "        weights,bias = self.params\n",
    "        return inputs@weights + bias\n",
    "    \n",
    "    # Le self() va déclencher le __call__()\n",
    "    def predict(self,inputs):\n",
    "        activations = self(inputs)\n",
    "        return activations > 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Les méthodes d'époque"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# On parcours les mini-batch et on va calculer les gradients puis appliquer la learning rate sur chaque paramètre\n",
    "def train_epoch(train_dl, model, loss_func, optim):\n",
    "    for xb, yb in train_dl:\n",
    "        compute_gradient(xb,yb,model,loss_func)\n",
    "        optim.adjust_params() # On modifie chaque paramètre en fonction du gradient et du learning rate défini\n",
    "        optim.zero_grad() # remise à zéros du gradient pour itération suivante. \n",
    "\n",
    "def compute_metric(xb, yb, model, metric):\n",
    "    activations = model(xb)\n",
    "    return metric(activations, yb)\n",
    "        \n",
    "# On parcours les mini batchs du dataset de validation et on calcule le taux de réussite avec le model actuel. \n",
    "# On retourne la moyenne de ces taux de réussite\n",
    "def validate_epoch(valid_dl, model, metric):\n",
    "        perfs = [compute_metric(xb, yb, model, metric) for xb,yb in valid_dl]\n",
    "        return round(torch.stack(perfs).mean().item(), 4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# La méthode d'entrainement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(dls, model, loss_func, metric, optim, epochs):\n",
    "    for i in range(epochs):\n",
    "        train_epoch(dls.train, model, loss_func, optim)\n",
    "        print(validate_epoch(dls.valid, model, metric), end=' ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6142 0.816 0.906 0.9286 0.9389 0.9465 0.9511 0.9521 0.9545 0.9555 0.9559 0.9579 0.9579 0.9584 0.9594 0.9598 0.9598 0.9598 0.9598 0.9608 0.9608 0.9608 0.9608 0.9613 0.9617 0.9632 0.9637 0.9637 0.9637 0.9642 0.9642 0.9642 0.9652 0.9652 0.9647 0.9642 0.9647 0.9647 0.9657 0.9657 "
     ]
    }
   ],
   "source": [
    "model = LinearModel()\n",
    "sgd = SGDOptimizer(model, lr=1)\n",
    "\n",
    "train_model(dls, model, loss_func=mnist_loss, metric=accuracy, optim=sgd, epochs=40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Méthodes Framework"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.Linear est l'équivalent de notre model linéaire. SGD l'équivalent de notre Optimiseur\n",
    "# Learner est l'objet de base pour regrouper le tout.\n",
    "learn = Learner(dls, nn.Linear(28*28,1), opt_func=SGD,\n",
    "                loss_func=mnist_loss, metrics=accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: left;\">\n",
       "      <th>epoch</th>\n",
       "      <th>train_loss</th>\n",
       "      <th>valid_loss</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0.637096</td>\n",
       "      <td>0.503325</td>\n",
       "      <td>0.495584</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0.473746</td>\n",
       "      <td>0.210929</td>\n",
       "      <td>0.814033</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0.175497</td>\n",
       "      <td>0.168145</td>\n",
       "      <td>0.850834</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0.077805</td>\n",
       "      <td>0.102601</td>\n",
       "      <td>0.914132</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0.041864</td>\n",
       "      <td>0.075889</td>\n",
       "      <td>0.933268</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0.027831</td>\n",
       "      <td>0.061218</td>\n",
       "      <td>0.949460</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0.022047</td>\n",
       "      <td>0.052023</td>\n",
       "      <td>0.956820</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0.019457</td>\n",
       "      <td>0.045877</td>\n",
       "      <td>0.962218</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0.018128</td>\n",
       "      <td>0.041531</td>\n",
       "      <td>0.965162</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0.017318</td>\n",
       "      <td>0.038301</td>\n",
       "      <td>0.967125</td>\n",
       "      <td>00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Revient à un appel de notre train_model.\n",
    "learn.fit(10, lr=1.)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
